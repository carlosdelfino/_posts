---
title: Introdução as Redes Neurais, Tipos de Redes Neurias e Modelos 
tags: [RNN, MI, LSTM, GRU, Redes Neurais, Inteligência Artificial, Inteligência, Artificial, RNN, NN, LTSM, Formulas, Rampa Simetrica, Simetrica, Ativação Lógistica, Hiperbólica, Tangente, Tangente Hiperbólica, Função Logistica]
categories: [redesneurais, introducao]
layout: article
share: true
toc: true
comments: true
feature:
 category: true
 index: true
tagcloud: true
ads: 
 show: true
image:
   teaser: redesneurais/rnn/lstm720x450.jpg
   feature: redesneurais/rnn/lstm720x450-2.jpg
math: true
---
Neste artigo quero anotar os típos e modelos de redes neurais, e até comentar um pouco sobre aplicações.

<!--more-->
## Termos a Qualificar

### Antagonistic receptive fields 

### PSTH output signal

### DOG (Difference Of Gaussians)


## Infraestrutura

### SVM

Support Vector Machine, Proposto por Vapnik



## Modelos de Redes Neurais

### BPTT

### RTRL

### Fuzzy Neural Network

### RNN

Recurrent Neural Network

#### Multiplicative RNN

#### Second Order RNN


#### RNN Linear

### BNN

Backpropagation Neural Network

As redes neurais do tipo Backpropagation possuem normalmente camadas internas (ocultas) e se utilizam de funções de ativação do tipo sigmoid.

Em redes neurais Backpropagation, o erro da camada interna é corrigido na próxima camada, assim se´da o Backpropagation.

### CNN

Convolucional Neural Network

### LTSM

Long Short Term Memory networks

### GRU

Gated Recurrent Units

### RBN

Recurrent Batch Normalization

### HMM

Hidden Markov Models

### MI

Muiltipla integração é uma modelo estrutural para redes neurais, recentemente criado para melhorar o desempenho das redes RNN.


#### MI-RNN

As redes RNN que usam uma camada MI tem as mesmas variantes RNN possíveis.

#### R-CNN

Regions com Convolutional Neural Networks (R-CNN) method proposto por Girshick para detecção de objetos.

#### Neuron model RF-PSTH 

## Algoritimos de Otimização

### Adam optimizer

### Neumann Optimizer

## Outras informações relevantes

### SRM

Structure risk minimization é um critério usado por SVM para construir um hiperplano para optimização de regressões ou classificações, tornando o mecanismo de aprendizado mais generalizado.

### BP

### FCM

### GK Fuzzy Cluster

### TK Fuzzy Model

### Hebbian principle

Dentro do que nos interessa o principio Hebbiano é quando dois neurónios são sempre ativados simultaneamente com frequência, significa que ambos estão relacionados, ou seja, representam o mesmo sinal, porém isso é uma simplificação perigosa, pois podem haver aprendizados que levam a resultados distintos caso um destes neurónios seja removidos.

### Neuromórfico

#### Hadamard product 

$$ \odot $$

$$
\emptyset = ((\alpha \odot Wx \odot Uz + \beta_1) \odot (Uz + \beta_2 \odot Wx + b))
$$


## Fontes:

* http://bit.ly/2KpBRPR
* [Advances in Neural Networks - ISNN 2007: 4th International Symposium](http://bit.ly/2HHI8og) 
* https://tek.io/2KlIAdH
* http://www.eng.monash.edu.au/non-cms/ecse/ieee/ieeebio2001/hasnain.pdf
* https://towardsdatascience.com/linear-algebra-cheat-sheet-for-deep-learning-cd67aba4526c
¨https://www.sciencedirect.com/topics/neuroscience/hebbian-theory
* https://arxiv.org/pdf/1606.06630.pdf
* [Neuron model RF-PSTH (which simulates Receptive Field (RF) structure and PSTH output signal of the neuron) ](http://neuroclusterbrain.com/neuron_model.html)
